{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-27T17:55:46.909362Z",
     "start_time": "2025-09-27T17:55:42.888855Z"
    }
   },
   "source": [
    "# step1_split.py\n",
    "import os, csv\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "# From Notebooks/, go up one level -> AI_ML_Project -> Data/Raw/Tea Leaf Disease Dataset\n",
    "DATASET_DIR = Path(\"../Data/Raw/Tea Leaf Disease Dataset\")\n",
    "OUT_DIR     = Path(\"../Data/Splits\")\n",
    "\n",
    "TEST_SIZE     = 0.20\n",
    "VAL_SIZE      = 0.10\n",
    "RANDOM_STATE  = 42\n",
    "# -----------------------------------------\n",
    "\n",
    "def list_images_with_labels(root_dir: Path):\n",
    "    \"\"\"Return (paths, labels) with paths relative to dataset root.\"\"\"\n",
    "    paths, labels = [], []\n",
    "    classes = [d for d in root_dir.iterdir() if d.is_dir() and not d.name.startswith(\"_\")]\n",
    "    if not classes:\n",
    "        raise ValueError(f\"No class folders found under: {root_dir}\")\n",
    "    for cls in sorted(classes):\n",
    "        for f in os.listdir(cls):\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")):\n",
    "                rel_path = cls / f   # keep path relative\n",
    "                paths.append(str(rel_path))\n",
    "                labels.append(cls.name)\n",
    "    return paths, labels\n",
    "\n",
    "def write_index_csv(index_tuples, out_csv: Path):\n",
    "    \"\"\"Write CSV file with [path,label].\"\"\"\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_csv.open(\"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"path\",\"label\"])\n",
    "        for p, y in index_tuples:\n",
    "            w.writerow([p, y])\n",
    "\n",
    "def stratified_split_index(\n",
    "    data_dir: Path, out_dir: Path,\n",
    "    test_size=0.20, val_size=0.10, random_state=42\n",
    "):\n",
    "    X, y = list_images_with_labels(data_dir)\n",
    "\n",
    "    if not X:\n",
    "        raise ValueError(f\"No images found under: {data_dir}\")\n",
    "\n",
    "    if not (0 < test_size < 1 and 0 < val_size < 1 and test_size + val_size < 1):\n",
    "        raise ValueError(\"test_size and val_size must be in (0,1) and sum to < 1.\")\n",
    "\n",
    "    # First split into Train vs (Val+Test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=test_size+val_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "    # Then split Val vs Test\n",
    "    rel_val = val_size / (test_size+val_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=1-rel_val, stratify=y_temp, random_state=random_state\n",
    "    )\n",
    "\n",
    "    write_index_csv(list(zip(X_train,y_train)), out_dir/\"train_index.csv\")\n",
    "    write_index_csv(list(zip(X_val,  y_val)),  out_dir/\"val_index.csv\")\n",
    "    write_index_csv(list(zip(X_test, y_test)), out_dir/\"test_index.csv\")\n",
    "\n",
    "    print(f\"Dataset split completed!\")\n",
    "    print(f\"Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "    print(f\"CSV files saved to: {out_dir.resolve()}\")\n",
    "\n",
    "    # Small preview\n",
    "    for split_name, fname in [(\"Train\", \"train_index.csv\"), (\"Val\", \"val_index.csv\"), (\"Test\", \"test_index.csv\")]:\n",
    "        fpath = out_dir / fname\n",
    "        with fpath.open() as f:\n",
    "            lines = f.readlines()\n",
    "        print(f\"\\n{split_name} CSV ({fname}): first 5 rows\")\n",
    "        print(\"\".join(lines[:6]))   # header + 5 rows\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "if __name__ == \"__main__\" or True:   # also works inside Jupyter\n",
    "    print(\"Using dataset at:\", DATASET_DIR.resolve())\n",
    "    stratified_split_index(\n",
    "        data_dir=DATASET_DIR,\n",
    "        out_dir=OUT_DIR,\n",
    "        test_size=TEST_SIZE,\n",
    "        val_size=VAL_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset at: C:\\Users\\Dell\\OneDrive\\Desktop\\2025-Y2-S1-MLB-WE1G2-01\\Data\\Raw\\Tea Leaf Disease Dataset\n",
      "Dataset split completed!\n",
      "Train: 22694 | Val: 3242 | Test: 6485\n",
      "CSV files saved to: C:\\Users\\Dell\\OneDrive\\Desktop\\2025-Y2-S1-MLB-WE1G2-01\\Data\\Splits\n",
      "\n",
      "Train CSV (train_index.csv): first 5 rows\n",
      "path,label\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\brown_blight\\brown_blight_0_1883.jpg,brown_blight\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\gray_blight\\gray_blight_0_2486.jpg,gray_blight\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\red_spot\\red_spot_0_3011.jpg,red_spot\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\brown_blight\\brown_blight_0_6824.jpg,brown_blight\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\healthy\\healthy_0_6006.jpg,healthy\n",
      "\n",
      "\n",
      "Val CSV (val_index.csv): first 5 rows\n",
      "path,label\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\gray_blight\\image_0_127.jpg,gray_blight\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\brown_blight\\brown_blight_0_7104.jpg,brown_blight\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\algal_spot\\algal_spot_0_6656.jpg,algal_spot\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\helopeltis\\20220101_103646.jpg,helopeltis\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\gray_blight\\20211228_131259.jpg,gray_blight\n",
      "\n",
      "\n",
      "Test CSV (test_index.csv): first 5 rows\n",
      "path,label\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\healthy\\healthy_0_1893.jpg,healthy\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\algal_spot\\algal_spot_0_8528.jpg,algal_spot\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\algal_spot\\algal_spot_0_4949.jpg,algal_spot\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\gray_blight\\gray_blight_0_7110.jpg,gray_blight\n",
      "..\\Data\\Raw\\Tea Leaf Disease Dataset\\algal_spot\\algal_spot_0_7785.jpg,algal_spot\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T17:55:54.080081Z",
     "start_time": "2025-09-27T17:55:53.987533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# aug_pytorch.py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATASET_ROOT = Path(\"../Data/Raw/Tea Leaf Disease Dataset\")  # where images live\n",
    "SPLITS_DIR   = Path(\"../Data/Splits\")                        # where CSVs live\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 32\n",
    "NUM_WORKERS  = 0\n",
    "PIN_MEMORY   = False\n",
    "# ----------------------------\n",
    "\n",
    "class CsvImageDataset(Dataset):\n",
    "    def __init__(self, csv_path: Path, root: Path, class_to_idx=None, transform=None):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.paths = df[\"path\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        if class_to_idx is None:\n",
    "            classes = sorted(set(self.labels))\n",
    "            self.class_to_idx = {c:i for i,c in enumerate(classes)}\n",
    "        else:\n",
    "            self.class_to_idx = class_to_idx\n",
    "        self.y = [self.class_to_idx[c] for c in self.labels]\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = Path(self.paths[idx])\n",
    "\n",
    "    # If the CSV already has an absolute or root-prefixed path, use it as-is.\n",
    "    # Otherwise, join it to self.root.\n",
    "        if p.is_absolute() or str(p).startswith(str(self.root)):\n",
    "            img_path = p\n",
    "        else:\n",
    "            img_path = self.root / p\n",
    "\n",
    "    # Normalize things like \".../root/../root/...\" to a clean path\n",
    "        img_path = img_path.resolve()\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.y[idx]\n",
    "# ---------- TRANSFORMS ----------\n",
    "# Train: heavier augments\n",
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(3/4, 4/3)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.1),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    T.RandomPerspective(distortion_scale=0.3, p=0.2),\n",
    "    T.RandomGrayscale(p=0.05),\n",
    "    T.ToTensor(),\n",
    "    # ImageNet normalization; replace with dataset mean/std if you computed them\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Val/Test: no heavy augments; just deterministic resize/crop\n",
    "eval_tf = T.Compose([\n",
    "    T.Resize(int(IMG_SIZE*1.14)),  # like torchvision eval recipe\n",
    "    T.CenterCrop(IMG_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ---------- DATASETS ----------\n",
    "train_csv = SPLITS_DIR / \"train_index.csv\"\n",
    "val_csv   = SPLITS_DIR / \"val_index.csv\"\n",
    "test_csv  = SPLITS_DIR / \"test_index.csv\"\n",
    "\n",
    "# Build train first to freeze class_to_idx mapping, then share it\n",
    "train_ds = CsvImageDataset(train_csv, DATASET_ROOT, transform=train_tf)\n",
    "class_to_idx = train_ds.class_to_idx\n",
    "\n",
    "val_ds   = CsvImageDataset(val_csv,   DATASET_ROOT, class_to_idx=class_to_idx, transform=eval_tf)\n",
    "test_ds  = CsvImageDataset(test_csv,  DATASET_ROOT, class_to_idx=class_to_idx, transform=eval_tf)\n",
    "\n",
    "# ---------- LOADERS ----------\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(\"Classes:\", class_to_idx)\n",
    "print(f\"Train/Val/Test sizes: {len(train_ds)} / {len(val_ds)} / {len(test_ds)}\")\n",
    "\n",
    "\n"
   ],
   "id": "933ec6f2b46c8dfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {'algal_spot': 0, 'brown_blight': 1, 'gray_blight': 2, 'healthy': 3, 'helopeltis': 4, 'red_spot': 5}\n",
      "Train/Val/Test sizes: 22694 / 3242 / 6485\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T18:12:25.651331Z",
     "start_time": "2025-09-27T18:00:52.254348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Undo normalization for saving\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "    return img_tensor * std + mean\n",
    "\n",
    "def save_full_augmented_dataset(dl, class_to_idx, save_dir=\"Augmented_Images\"):\n",
    "    inv_map = {v: k for k, v in class_to_idx.items()}\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    for batch_idx, (imgs, labels) in enumerate(dl):\n",
    "        for i in range(len(imgs)):\n",
    "            class_name = inv_map[labels[i].item()]\n",
    "            class_dir = os.path.join(save_dir, class_name)\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "            # Unique filename using a global counter\n",
    "            out_path = os.path.join(class_dir, f\"{class_name}_{count}.png\")\n",
    "            vutils.save_image(denormalize(imgs[i]), out_path)\n",
    "            count += 1\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:  # progress log every 10 batches\n",
    "            print(f\"Processed {count} images...\")\n",
    "\n",
    "    print(f\"\\n Done! Saved {count} augmented images to: {save_dir}\")\n",
    "\n",
    "# ===========================\n",
    "# Example usage\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n Saving FULL augmented training dataset...\")\n",
    "save_full_augmented_dataset(train_loader, class_to_idx, save_dir=\"Augmented_Images/Train\")\n",
    "\n",
    "print(\"\\n Saving FULL validation dataset (no augmentation, just rescaled)...\")\n",
    "save_full_augmented_dataset(val_loader, class_to_idx, save_dir=\"Augmented_Images/Val\")\n"
   ],
   "id": "6b5e80e586bf5296",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saving FULL augmented training dataset...\n",
      "Processed 320 images...\n",
      "Processed 640 images...\n",
      "Processed 960 images...\n",
      "Processed 1280 images...\n",
      "Processed 1600 images...\n",
      "Processed 1920 images...\n",
      "Processed 2240 images...\n",
      "Processed 2560 images...\n",
      "Processed 2880 images...\n",
      "Processed 3200 images...\n",
      "Processed 3520 images...\n",
      "Processed 3840 images...\n",
      "Processed 4160 images...\n",
      "Processed 4480 images...\n",
      "Processed 4800 images...\n",
      "Processed 5120 images...\n",
      "Processed 5440 images...\n",
      "Processed 5760 images...\n",
      "Processed 6080 images...\n",
      "Processed 6400 images...\n",
      "Processed 6720 images...\n",
      "Processed 7040 images...\n",
      "Processed 7360 images...\n",
      "Processed 7680 images...\n",
      "Processed 8000 images...\n",
      "Processed 8320 images...\n",
      "Processed 8640 images...\n",
      "Processed 8960 images...\n",
      "Processed 9280 images...\n",
      "Processed 9600 images...\n",
      "Processed 9920 images...\n",
      "Processed 10240 images...\n",
      "Processed 10560 images...\n",
      "Processed 10880 images...\n",
      "Processed 11200 images...\n",
      "Processed 11520 images...\n",
      "Processed 11840 images...\n",
      "Processed 12160 images...\n",
      "Processed 12480 images...\n",
      "Processed 12800 images...\n",
      "Processed 13120 images...\n",
      "Processed 13440 images...\n",
      "Processed 13760 images...\n",
      "Processed 14080 images...\n",
      "Processed 14400 images...\n",
      "Processed 14720 images...\n",
      "Processed 15040 images...\n",
      "Processed 15360 images...\n",
      "Processed 15680 images...\n",
      "Processed 16000 images...\n",
      "Processed 16320 images...\n",
      "Processed 16640 images...\n",
      "Processed 16960 images...\n",
      "Processed 17280 images...\n",
      "Processed 17600 images...\n",
      "Processed 17920 images...\n",
      "Processed 18240 images...\n",
      "Processed 18560 images...\n",
      "Processed 18880 images...\n",
      "Processed 19200 images...\n",
      "Processed 19520 images...\n",
      "Processed 19840 images...\n",
      "Processed 20160 images...\n",
      "Processed 20480 images...\n",
      "Processed 20800 images...\n",
      "Processed 21120 images...\n",
      "Processed 21440 images...\n",
      "Processed 21760 images...\n",
      "Processed 22080 images...\n",
      "Processed 22400 images...\n",
      "Processed 22694 images...\n",
      "\n",
      "âœ… Done! Saved 22694 augmented images to: Augmented_Images/Train\n",
      "\n",
      "ðŸ’¾ Saving FULL validation dataset (no augmentation, just rescaled)...\n",
      "Processed 320 images...\n",
      "Processed 640 images...\n",
      "Processed 960 images...\n",
      "Processed 1280 images...\n",
      "Processed 1600 images...\n",
      "Processed 1920 images...\n",
      "Processed 2240 images...\n",
      "Processed 2560 images...\n",
      "Processed 2880 images...\n",
      "Processed 3200 images...\n",
      "\n",
      "âœ… Done! Saved 3242 augmented images to: Augmented_Images/Val\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
