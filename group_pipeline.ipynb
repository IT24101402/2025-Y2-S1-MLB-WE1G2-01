{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:25:29.423295Z",
     "start_time": "2025-09-27T14:25:21.291498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, csv, hashlib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image, UnidentifiedImageError, ImageFile\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import os, json, csv, random\n",
    "from collections import Counter, defaultdict\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, csv\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "31e7babd3b9936cd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:25:32.275690Z",
     "start_time": "2025-09-27T14:25:32.272015Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = \"Tea Leaf Disease Dataset\"",
   "id": "1cbb5546b0915fd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T15:06:03.205350Z",
     "start_time": "2025-09-27T15:01:32.795802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pipeline.py (complete pipeline with all 6 preprocessing steps)\n",
    "import os, csv, hashlib, shutil, random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- PATH RESOLVER ----------------\n",
    "def resolve_raw_root() -> Path:\n",
    "    \"\"\"Find '../Data/Raw/Tea Leaf Disease Dataset' (or close variants).\"\"\"\n",
    "    name = \"Tea Leaf Disease Dataset\"\n",
    "    cwd = Path.cwd()\n",
    "    candidates = [\n",
    "        cwd / \"Data\" / \"Raw\" / name,\n",
    "        cwd / \"..\" / \"Data\" / \"Raw\" / name,\n",
    "        cwd / \"..\" / \"..\" / \"Data\" / \"Raw\" / name,\n",
    "        cwd / name,\n",
    "        cwd / \"..\" / name,\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.is_dir():\n",
    "            print(f\"Using RAW_ROOT: {p.resolve()}\")\n",
    "            return p.resolve()\n",
    "    tried = \"\\n - \".join(str(p.resolve()) for p in candidates)\n",
    "    raise FileNotFoundError(f\"Couldn't find raw dataset folder. Tried:\\n{tried}\")\n",
    "\n",
    "RAW_ROOT = resolve_raw_root()\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "RESULTS_DIR     = Path(\"../results\")\n",
    "PREP_IMG_DIR    = RESULTS_DIR / \"Preprocessed_Images\"\n",
    "SPLITS_DIR      = Path(\"../Data/Splits\")\n",
    "OVERSAMPLED_CSV = RESULTS_DIR / \"Splits\" / \"train_oversampled.csv\"\n",
    "LOG_CSV         = RESULTS_DIR / \"clean_log.csv\"\n",
    "\n",
    "PREP_IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS_DIR / \"Splits\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cleaning\n",
    "SCAN_EXTS        = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tif\", \".tiff\")\n",
    "DISALLOWED_EXTS  = (\".bmp\", \".webp\", \".tif\", \".tiff\", \".jpeg\")\n",
    "REQUIRE_RGB      = True\n",
    "MIN_SIDE         = 64\n",
    "MAX_ASPECT       = 3.0\n",
    "CHECK_MD5_DUPES  = True\n",
    "CHECK_PHASH_NEAR = True\n",
    "\n",
    "# Resizing\n",
    "TARGET_SIZE      = (224, 224)\n",
    "SAVE_EXT         = \".jpg\"\n",
    "\n",
    "# Normalization\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD  = [0.229, 0.224, 0.225]\n",
    "NORM_DIR = RESULTS_DIR / \"Normalized_Arrays\"\n",
    "NORM_PREVIEW_DIR = RESULTS_DIR / \"Normalized_Previews\"\n",
    "\n",
    "# Augmentation\n",
    "N_AUG = 2\n",
    "AUG_TF = T.Compose([\n",
    "    T.RandomResizedCrop((TARGET_SIZE[1], TARGET_SIZE[0]), scale=(0.8, 1.0), ratio=(3/4, 4/3)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.1),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    T.RandomPerspective(distortion_scale=0.25, p=0.2),\n",
    "])\n",
    "AUG_IMG_DIR = RESULTS_DIR / \"Augmented_Images\"\n",
    "\n",
    "# Splits\n",
    "TEST_SIZE        = 0.20\n",
    "VAL_SIZE         = 0.10\n",
    "RANDOM_STATE     = 42\n",
    "\n",
    "# Oversampling\n",
    "OVERSAMPLE_TO_MAX = True\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def list_class_dirs(root: Path) -> List[Path]:\n",
    "    return sorted([d for d in root.iterdir() if d.is_dir() and not d.name.startswith(\"_\")])\n",
    "\n",
    "def file_md5(path: Path, chunk=8192) -> str:\n",
    "    m = hashlib.md5()\n",
    "    with path.open(\"rb\") as f:\n",
    "        for blk in iter(lambda: f.read(chunk), b\"\"):\n",
    "            m.update(blk)\n",
    "    return m.hexdigest()\n",
    "\n",
    "def phash_hex(path: Path, hash_size=8) -> str:\n",
    "    with Image.open(path) as im:\n",
    "        im = im.convert(\"L\").resize((hash_size, hash_size), Image.LANCZOS)\n",
    "        px = np.array(im, dtype=np.float32)\n",
    "        avg = px.mean()\n",
    "        bits = (px > avg).astype(np.uint8).flatten()\n",
    "        return f\"{int(''.join(map(str,bits)), 2):016x}\"\n",
    "\n",
    "def safe_save(img: Image.Image, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    base, ext = os.path.splitext(dst)\n",
    "    k, final = 1, dst\n",
    "    while Path(final).exists():\n",
    "        final = Path(f\"{base}__dup{k}{ext}\")\n",
    "        k += 1\n",
    "    img.save(final, quality=95)\n",
    "\n",
    "def resize_img(p: Path, size=(224,224)) -> Image.Image:\n",
    "    with Image.open(p) as im:\n",
    "        im = im.convert(\"RGB\")\n",
    "        return im.resize(size, Image.BILINEAR)\n",
    "\n",
    "# ---------------- STEP 1: CLEAN ----------------\n",
    "def scan_and_clean(root: Path):\n",
    "    issues, survivors_by_class = [], defaultdict(list)\n",
    "    before_counts, after_counts = {}, {}\n",
    "\n",
    "    for cls_dir in list_class_dirs(root):\n",
    "        cls = cls_dir.name\n",
    "        files = [f for f in cls_dir.iterdir() if f.suffix.lower() in SCAN_EXTS]\n",
    "        before_counts[cls] = len(files)\n",
    "        valid = 0\n",
    "\n",
    "        for f in files:\n",
    "            ext = f.suffix.lower()\n",
    "            if ext in DISALLOWED_EXTS:\n",
    "                issues.append([cls, str(f), f\"Disallowed extension: {ext}\"])\n",
    "                continue\n",
    "            if f.stat().st_size == 0:\n",
    "                issues.append([cls, str(f), \"Zero-byte file\"])\n",
    "                continue\n",
    "            try:\n",
    "                with Image.open(f) as im: im.verify()\n",
    "                with Image.open(f) as im:\n",
    "                    im.load()\n",
    "                    mode, (w,h) = im.mode, im.size\n",
    "            except Exception as e:\n",
    "                issues.append([cls, str(f), f\"Unreadable: {e}\"])\n",
    "                continue\n",
    "            if REQUIRE_RGB and mode != \"RGB\":\n",
    "                issues.append([cls, str(f), f\"Invalid mode: {mode}\"])\n",
    "                continue\n",
    "            if min(w,h) < MIN_SIDE or max(w,h)/max(1,min(w,h)) > MAX_ASPECT:\n",
    "                issues.append([cls, str(f), f\"Invalid size: {w}x{h}\"])\n",
    "                continue\n",
    "            survivors_by_class[cls].append(f); valid += 1\n",
    "        after_counts[cls] = valid\n",
    "\n",
    "    # Duplicates\n",
    "    if CHECK_MD5_DUPES or CHECK_PHASH_NEAR:\n",
    "        for cls, paths in survivors_by_class.items():\n",
    "            keep = paths\n",
    "            if CHECK_MD5_DUPES:\n",
    "                md5_map = defaultdict(list)\n",
    "                for p in paths: md5_map[file_md5(p)].append(p)\n",
    "                keep = [group[0] for group in md5_map.values()]\n",
    "            if CHECK_PHASH_NEAR:\n",
    "                phash_map = defaultdict(list)\n",
    "                for p in keep: phash_map[phash_hex(p)].append(p)\n",
    "                keep = [group[0] for group in phash_map.values()]\n",
    "            survivors_by_class[cls] = keep\n",
    "            after_counts[cls] = len(keep)\n",
    "\n",
    "    with LOG_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"class\",\"path\",\"reason\"]); w.writerows(issues)\n",
    "\n",
    "    return survivors_by_class, before_counts, after_counts, issues\n",
    "\n",
    "# ---------------- STEP 2: RESIZE ----------------\n",
    "def write_preprocessed_images(survivors_by_class, out_dir: Path, size=(224,224)):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    count = 0\n",
    "    for cls, files in survivors_by_class.items():\n",
    "        dst_cls = out_dir / cls\n",
    "        dst_cls.mkdir(parents=True, exist_ok=True)\n",
    "        for f in files:\n",
    "            try:\n",
    "                imr = resize_img(f, size=size)\n",
    "                dst = dst_cls / (f.stem + SAVE_EXT)\n",
    "                safe_save(imr, dst); count += 1\n",
    "            except Exception: pass\n",
    "    return count\n",
    "\n",
    "# ---------------- STEP 2.5: NORMALIZATION ----------------\n",
    "def offline_normalize_all(prep_root: Path, npy_dir: Path, preview_dir: Path, limit_preview_per_class=10):\n",
    "    npy_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preview_dir.mkdir(parents=True, exist_ok=True)\n",
    "    saved_count, preview_count = 0, defaultdict(int)\n",
    "\n",
    "    def to_tensor(img): return T.ToTensor()(img)\n",
    "    norm = T.Normalize(mean=NORM_MEAN, std=NORM_STD)\n",
    "\n",
    "    for cls_dir in list_class_dirs(prep_root):\n",
    "        cls = cls_dir.name\n",
    "        out_cls_npy, out_cls_prev = npy_dir/cls, preview_dir/cls\n",
    "        out_cls_npy.mkdir(parents=True, exist_ok=True)\n",
    "        out_cls_prev.mkdir(parents=True, exist_ok=True)\n",
    "        for f in cls_dir.glob(\"*.jpg\"):\n",
    "            try:\n",
    "                with Image.open(f) as im:\n",
    "                    im = im.convert(\"RGB\")\n",
    "                    x = to_tensor(im); x_norm = norm(x)\n",
    "                    np.save(out_cls_npy / (f.stem + \".npy\"), x_norm.numpy().astype('float32'))\n",
    "                    saved_count += 1\n",
    "                    if preview_count[cls] < limit_preview_per_class:\n",
    "                        mean = torch.tensor(NORM_MEAN).view(3,1,1)\n",
    "                        std  = torch.tensor(NORM_STD).view(3,1,1)\n",
    "                        x_prev = (x_norm*std + mean).clamp(0,1)\n",
    "                        Image.fromarray((x_prev.permute(1,2,0).numpy()*255).astype('uint8')).save(\n",
    "                            out_cls_prev / (f.stem+\"_denorm.jpg\"), quality=95)\n",
    "                        preview_count[cls]+=1\n",
    "            except Exception: pass\n",
    "    print(f\"Normalized .npy saved: {saved_count}\")\n",
    "\n",
    "# ---------------- STEP 3: SPLITS ----------------\n",
    "def list_images_with_labels(root: Path) -> Tuple[List[str], List[str]]:\n",
    "    paths, labels = [], []\n",
    "    for cls_dir in list_class_dirs(root):\n",
    "        cls = cls_dir.name\n",
    "        for f in cls_dir.glob(\"*.jpg\"):\n",
    "            rel = f.relative_to(root); paths.append(str(rel)); labels.append(cls)\n",
    "    return paths, labels\n",
    "\n",
    "def ensure_splits(prep_root: Path, splits_dir: Path, test=0.20, val=0.10, seed=42):\n",
    "    tcsv, vcsv, scsv = splits_dir/\"train_index.csv\", splits_dir/\"val_index.csv\", splits_dir/\"test_index.csv\"\n",
    "    if tcsv.exists() and vcsv.exists() and scsv.exists(): return\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = list_images_with_labels(prep_root)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test+val, stratify=y, random_state=seed)\n",
    "    rel_val = val/(test+val)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1-rel_val, stratify=y_temp, random_state=seed)\n",
    "    splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for name, Xs, Ys in [(\"train_index.csv\",X_train,y_train),(\"val_index.csv\",X_val,y_val),(\"test_index.csv\",X_test,y_test)]:\n",
    "        with (splits_dir/name).open(\"w\", newline=\"\") as f: csv.writer(f).writerows([[\"path\",\"label\"],*zip(Xs,Ys)])\n",
    "\n",
    "# ---------------- STEP 3.5: AUGMENTATION ----------------\n",
    "def augment_training_split(prep_root: Path, splits_dir: Path, out_img_dir: Path, n_aug=N_AUG):\n",
    "    train_csv = splits_dir / \"train_index.csv\"; assert train_csv.exists()\n",
    "    rows = pd.read_csv(train_csv).to_records(index=False)\n",
    "    aug_rows, total_aug = [], 0\n",
    "    out_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for rel_path, label in rows:\n",
    "        try:\n",
    "            im = Image.open(prep_root/rel_path).convert(\"RGB\")\n",
    "            dst_cls = out_img_dir/label; dst_cls.mkdir(parents=True, exist_ok=True)\n",
    "            for k in range(n_aug):\n",
    "                aug_img = AUG_TF(im); aug_name = f\"{Path(rel_path).stem}_aug{k}{SAVE_EXT}\"\n",
    "                aug_path = dst_cls/aug_name; aug_img.save(aug_path, quality=95)\n",
    "                aug_rows.append((str(aug_path.relative_to(out_img_dir)), label)); total_aug+=1\n",
    "        except Exception: pass\n",
    "    combined_csv = splits_dir / \"train_index_augmented.csv\"\n",
    "    with combined_csv.open(\"w\", newline=\"\") as f:\n",
    "        w=csv.writer(f); w.writerow([\"root\",\"path\",\"label\"])\n",
    "        for rel_path,label in rows: w.writerow([str(prep_root.resolve()), rel_path, label])\n",
    "        for rel_aug,label in aug_rows: w.writerow([str(out_img_dir.resolve()), rel_aug, label])\n",
    "    print(f\"Augmented images: {total_aug}\")\n",
    "\n",
    "# ---------------- STEP 4: OVERSAMPLING ----------------\n",
    "def write_oversampled_csv(train_csv: Path, out_csv: Path):\n",
    "    df = pd.read_csv(train_csv)\n",
    "    by_cls = df.groupby(\"label\")[\"path\"].apply(list).to_dict()\n",
    "    max_count = max(len(v) for v in by_cls.values())\n",
    "    rows = []\n",
    "    for cls, paths in by_cls.items():\n",
    "        take = (paths*((max_count+len(paths)-1)//len(paths)))[:max_count]\n",
    "        rows.extend([(p,cls) for p in take])\n",
    "    random.seed(RANDOM_STATE); random.shuffle(rows)\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_csv.open(\"w\", newline=\"\") as f: csv.writer(f).writerows([[\"path\",\"label\"],*rows])\n",
    "    print(\"Oversampled train CSV:\", out_csv.resolve())\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "if __name__==\"__main__\":\n",
    "    survivors, before, after, issues = scan_and_clean(RAW_ROOT)\n",
    "    print(\"CLEAN SUMMARY:\"); [print(c,before[c],after[c]) for c in sorted(before)]\n",
    "    count = write_preprocessed_images(survivors, PREP_IMG_DIR, size=TARGET_SIZE)\n",
    "    print(f\"Wrote {count} resized images -> {PREP_IMG_DIR}\")\n",
    "    offline_normalize_all(PREP_IMG_DIR, NORM_DIR, NORM_PREVIEW_DIR)\n",
    "    ensure_splits(PREP_IMG_DIR, SPLITS_DIR, test=TEST_SIZE, val=VAL_SIZE, seed=RANDOM_STATE)\n",
    "    augment_training_split(PREP_IMG_DIR, SPLITS_DIR, AUG_IMG_DIR, n_aug=N_AUG)\n",
    "    train_csv = SPLITS_DIR/\"train_index.csv\"\n",
    "    if train_csv.exists(): write_oversampled_csv(train_csv, OVERSAMPLED_CSV)\n",
    "    print(\"\\n Pipeline complete.\")"
   ],
   "id": "22f15c95c528c4a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RAW_ROOT: /Users/tharukakumarasiri/Desktop/AI_ML_Project/Data/Raw/Tea Leaf Disease Dataset\n",
      "CLEAN SUMMARY:\n",
      "algal_spot 5497 5135\n",
      "brown_blight 4908 4810\n",
      "gray_blight 5537 5121\n",
      "healthy 5492 4990\n",
      "helopeltis 5482 5254\n",
      "red_spot 5505 5266\n",
      "Wrote 30576 resized images -> ../results/Preprocessed_Images\n",
      "Normalized .npy saved: 61152\n",
      "Augmented images: 42806\n",
      "Oversampled train CSV: /Users/tharukakumarasiri/Desktop/results/Splits/train_oversampled.csv\n",
      "\n",
      " Pipeline complete.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T15:29:40.276323Z",
     "start_time": "2025-09-27T15:29:39.582872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# What does the pipeline think \"results\" is?\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_CWD.parent       # because your notebooks live in .../AI_ML_Project/Notebooks\n",
    "RESULTS_DIR  = PROJECT_ROOT / \"results\"\n",
    "PREP_IMG_DIR = RESULTS_DIR / \"Preprocessed_Images\"\n",
    "AUG_IMG_DIR  = RESULTS_DIR / \"Augmented_Images\"\n",
    "NORM_DIR     = RESULTS_DIR / \"Normalized\"\n",
    "\n",
    "print(\"Notebook CWD        :\", NOTEBOOK_CWD)\n",
    "print(\"Project root (expected):\", PROJECT_ROOT)\n",
    "print(\"RESULTS_DIR (expected):\", RESULTS_DIR.resolve())\n",
    "print(\"Preprocessed dir     :\", PREP_IMG_DIR.resolve())\n",
    "print(\"Exists?              :\", PREP_IMG_DIR.exists())\n",
    "\n",
    "# How many files do we actually have there?\n",
    "jpgs = list(PREP_IMG_DIR.rglob(\"*.jpg\")) if PREP_IMG_DIR.exists() else []\n",
    "print(\"Sample count in Preprocessed_Images:\", len(jpgs))\n",
    "print(\"First 5:\", [p.relative_to(PROJECT_ROOT) for p in jpgs[:5]])"
   ],
   "id": "8fa663479d27588e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook CWD        : /Users/tharukakumarasiri/Desktop/AI_ML_Project\n",
      "Project root (expected): /Users/tharukakumarasiri/Desktop\n",
      "RESULTS_DIR (expected): /Users/tharukakumarasiri/Desktop/results\n",
      "Preprocessed dir     : /Users/tharukakumarasiri/Desktop/results/Preprocessed_Images\n",
      "Exists?              : True\n",
      "Sample count in Preprocessed_Images: 61152\n",
      "First 5: [PosixPath('results/Preprocessed_Images/healthy/healthy_0_7840__dup1.jpg'), PosixPath('results/Preprocessed_Images/healthy/healthy_0_2462__dup1.jpg'), PosixPath('results/Preprocessed_Images/healthy/healthy_0_7889__dup1.jpg'), PosixPath('results/Preprocessed_Images/healthy/healthy_0_2181__dup1.jpg'), PosixPath('results/Preprocessed_Images/healthy/healthy_0_9894__dup1.jpg')]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T15:36:46.016389Z",
     "start_time": "2025-09-27T15:34:16.624639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, csv, json, random, shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "PREP_IMG_DIR   = Path(\"../results/Preprocessed_Images\")  # cleaned + resized 224x224 JPGs\n",
    "AUG_IMG_DIR    = Path(\"../results/Augmented_Images\")     # offline augs (if you created them)\n",
    "SPLITS_DIR     = Path(\"../Data/Splits\")                  # train/val/test CSVs here\n",
    "\n",
    "FINAL_DIR      = Path(\"../results/Final_Preprocessed_Dataset\")  # <-- ONE folder\n",
    "INCLUDE_AUG    = True         # put all augmented images into train\n",
    "ADD_COLOR_CONV = True         # add HSV/LAB/YUV converted copies (train only)\n",
    "BALANCE_TRAIN  = True         # oversample (by copying) to max class size (train only)\n",
    "SEED           = 42\n",
    "\n",
    "# Normalization you’ll use during training (recorded in _meta/norm_stats.json)\n",
    "NORM_MEAN = [0.485, 0.456, 0.406]\n",
    "NORM_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# ---------- UTILS ----------\n",
    "def read_split(csv_path: Path) -> List[tuple]:\n",
    "    rows = []\n",
    "    with csv_path.open() as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rows.append((row[\"path\"], row[\"label\"]))\n",
    "    return rows\n",
    "\n",
    "def copy_with_unique(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    base = dst.with_suffix('')\n",
    "    ext = dst.suffix\n",
    "    i, final = 1, dst\n",
    "    while final.exists():\n",
    "        final = Path(str(base) + f\"__dup{i}\" + ext)\n",
    "        i += 1\n",
    "    shutil.copy2(src, final)\n",
    "    return final\n",
    "\n",
    "def color_convert_variants(img_bgr):\n",
    "    out = []\n",
    "    # HSV\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    hsv_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    out.append((\"hsv\", hsv_bgr))\n",
    "    # LAB\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    lab_bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    out.append((\"lab\", lab_bgr))\n",
    "    # YUV\n",
    "    yuv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YUV)\n",
    "    yuv_bgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "    out.append((\"yuv\", yuv_bgr))\n",
    "    return out\n",
    "\n",
    "def gather_augmented_for_class(cls: str) -> List[Path]:\n",
    "    \"\"\"Return all augmented files for a class if AUG_IMG_DIR exists.\"\"\"\n",
    "    if not AUG_IMG_DIR.exists():\n",
    "        return []\n",
    "    cls_dir = AUG_IMG_DIR / cls\n",
    "    if not cls_dir.exists():\n",
    "        return []\n",
    "    return [p for p in cls_dir.glob(\"*.jpg\")]\n",
    "\n",
    "def ensure_clean_dir(path: Path):\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- BUILD ----------\n",
    "def build_final_dataset():\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # 0) Read splits\n",
    "    train_rows = read_split(SPLITS_DIR / \"train_index.csv\")\n",
    "    val_rows   = read_split(SPLITS_DIR / \"val_index.csv\")\n",
    "    test_rows  = read_split(SPLITS_DIR / \"test_index.csv\")\n",
    "\n",
    "    ensure_clean_dir(FINAL_DIR)\n",
    "    (FINAL_DIR / \"train\").mkdir()\n",
    "    (FINAL_DIR / \"val\").mkdir()\n",
    "    (FINAL_DIR / \"test\").mkdir()\n",
    "    (FINAL_DIR / \"_meta\").mkdir()\n",
    "\n",
    "    # 1) Copy base preprocessed images for each split\n",
    "    def copy_split(rows, split_name):\n",
    "        per_class_paths = defaultdict(list)\n",
    "        for rel, cls in tqdm(rows, desc=f\"Copying base {split_name}\"):\n",
    "            src = PREP_IMG_DIR / rel  # paths in CSV are relative to PREP_IMG_DIR\n",
    "            if not src.exists():\n",
    "                # fall back: some CSVs may store just filename; try class join\n",
    "                src = PREP_IMG_DIR / cls / Path(rel).name\n",
    "            if not src.exists():\n",
    "                # skip silently if truly missing\n",
    "                continue\n",
    "            dst = FINAL_DIR / split_name / cls / src.name\n",
    "            final = copy_with_unique(src, dst)\n",
    "            per_class_paths[cls].append(final)\n",
    "        return per_class_paths\n",
    "\n",
    "    train_paths = copy_split(train_rows, \"train\")\n",
    "    val_paths   = copy_split(val_rows,   \"val\")\n",
    "    test_paths  = copy_split(test_rows,  \"test\")\n",
    "\n",
    "    # 2) Add augmentations to TRAIN\n",
    "    aug_added = 0\n",
    "    if INCLUDE_AUG and AUG_IMG_DIR.exists():\n",
    "        for cls in train_paths.keys():\n",
    "            aug_files = gather_augmented_for_class(cls)\n",
    "            for src in tqdm(aug_files, desc=f\"Adding aug -> train/{cls}\", leave=False):\n",
    "                dst = FINAL_DIR / \"train\" / cls / src.name\n",
    "                copy_with_unique(src, dst)\n",
    "                aug_added += 1\n",
    "\n",
    "    # 3) Add colour-conversion variants for TRAIN (optional)\n",
    "    cc_added = 0\n",
    "    if ADD_COLOR_CONV:\n",
    "        for cls in train_paths.keys():\n",
    "            cls_dir = FINAL_DIR / \"train\" / cls\n",
    "            originals = [p for p in cls_dir.glob(\"*.jpg\")]\n",
    "            for src in tqdm(originals, desc=f\"Color convert -> train/{cls}\", leave=False):\n",
    "                img = cv2.imread(str(src))\n",
    "                if img is None:\n",
    "                    continue\n",
    "                for tag, var in color_convert_variants(img):\n",
    "                    dst = src.with_name(src.stem + f\"__{tag}\" + src.suffix)\n",
    "                    if not dst.exists():\n",
    "                        cv2.imwrite(str(dst), var)\n",
    "                        cc_added += 1\n",
    "\n",
    "    # 4) Balance TRAIN by oversampling (duplicate copies) to max class size\n",
    "    balanced_added = 0\n",
    "    if BALANCE_TRAIN:\n",
    "        counts = {}\n",
    "        for cls in (FINAL_DIR / \"train\").iterdir():\n",
    "            if cls.is_dir():\n",
    "                counts[cls.name] = len(list(cls.glob(\"*.jpg\")))\n",
    "        if counts:\n",
    "            target = max(counts.values())\n",
    "            for cls, n in counts.items():\n",
    "                if n >= target:\n",
    "                    continue\n",
    "                cls_dir = FINAL_DIR / \"train\" / cls\n",
    "                imgs = list(cls_dir.glob(\"*.jpg\"))\n",
    "                need = target - n\n",
    "                for i in range(need):\n",
    "                    src = imgs[i % len(imgs)]\n",
    "                    dst = cls_dir / (src.stem + f\"__os{i}\" + src.suffix)\n",
    "                    shutil.copy2(src, dst)\n",
    "                    balanced_added += 1\n",
    "\n",
    "    # 5) Write meta info (normalization and counts)\n",
    "    meta = {\n",
    "        \"normalization\": {\"mean\": NORM_MEAN, \"std\": NORM_STD},\n",
    "        \"include_aug\": INCLUDE_AUG,\n",
    "        \"add_color_converted\": ADD_COLOR_CONV,\n",
    "        \"balanced_train\": BALANCE_TRAIN,\n",
    "    }\n",
    "    with (FINAL_DIR / \"_meta\" / \"norm_stats.json\").open(\"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    # simple count report\n",
    "    report_lines = []\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_dir = FINAL_DIR / split\n",
    "        per_cls = {d.name: len(list((split_dir / d.name).glob(\"*.jpg\")))\n",
    "                   for d in split_dir.iterdir() if d.is_dir()}\n",
    "        total = sum(per_cls.values())\n",
    "        report_lines.append(f\"{split}: {total} images\\n\" +\n",
    "                            \"\\n\".join([f\"  - {k}: {v}\" for k,v in sorted(per_cls.items())]))\n",
    "    report_lines.append(f\"\\nAugmentations added: {aug_added}\")\n",
    "    report_lines.append(f\"Color-converted added: {cc_added}\")\n",
    "    report_lines.append(f\"Balanced copies added: {balanced_added}\")\n",
    "\n",
    "    (FINAL_DIR / \"_meta\" / \"build_report.txt\").write_text(\"\\n\\n\".join(report_lines))\n",
    "    print(\"\\n=== FINAL DATASET BUILT ===\")\n",
    "    print(\"\\n\".join(report_lines))\n",
    "    print(\"\\nSaved to:\", FINAL_DIR.resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_final_dataset()"
   ],
   "id": "aecd596dbe51001e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying base train: 100%|██████████| 21403/21403 [00:10<00:00, 2005.89it/s]\n",
      "Copying base val: 100%|██████████| 3057/3057 [00:02<00:00, 1337.79it/s]\n",
      "Copying base test: 100%|██████████| 6116/6116 [00:03<00:00, 1738.34it/s]\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL DATASET BUILT ===\n",
      "train: 265392 images\n",
      "  - algal_spot: 44232\n",
      "  - brown_blight: 44232\n",
      "  - gray_blight: 44232\n",
      "  - healthy: 44232\n",
      "  - helopeltis: 44232\n",
      "  - red_spot: 44232\n",
      "val: 3057 images\n",
      "  - algal_spot: 514\n",
      "  - brown_blight: 481\n",
      "  - gray_blight: 512\n",
      "  - healthy: 499\n",
      "  - helopeltis: 525\n",
      "  - red_spot: 526\n",
      "test: 6116 images\n",
      "  - algal_spot: 1027\n",
      "  - brown_blight: 962\n",
      "  - gray_blight: 1024\n",
      "  - healthy: 998\n",
      "  - helopeltis: 1051\n",
      "  - red_spot: 1054\n",
      "\n",
      "Augmentations added: 42806\n",
      "Color-converted added: 192627\n",
      "Balanced copies added: 8556\n",
      "\n",
      "Saved to: /Users/tharukakumarasiri/Desktop/results/Final_Preprocessed_Dataset\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
